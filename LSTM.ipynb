{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiesel : airsense_env_tsai_031\n",
    "from imports import * \n",
    "from functions import *\n",
    "from archs import *\n",
    "from mylearner import *\n",
    "%matplotlib inline\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading annotated data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loading_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode target classes (person and window open) classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = encode_classes(d1)\n",
    "df2 = encode_classes(d2)\n",
    "df = encode_classes(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**filtering data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2s column has only NaN values, also drop timestamp,datetime,deviceid\n",
    "df.drop(columns=['h2s','timestamp','deviceid'],inplace=True)\n",
    "df1.drop(columns=['h2s','timestamp','deviceid'],inplace=True)\n",
    "df2.drop(columns=['h2s','timestamp','deviceid'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values, drop NAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing(df1)\n",
    "plot_missing(df2)\n",
    "\n",
    "#### substitute NaN values with mean \n",
    "## polynomial interpolation with degree > 1 uses index, also convert dtype to float to work\n",
    "df1 = impute_NaN(df1)\n",
    "df2 = impute_NaN(df2)\n",
    "############## conmbine into df \n",
    "\n",
    "df = concat(df1,df2)\n",
    "df.columns=df1.columns\n",
    "\n",
    "### drop datetime column and store it before for visualization\n",
    "datetime_df = df.datetime\n",
    "datetime_df1 = df1.datetime\n",
    "datetime_df2 = df2.datetime\n",
    "\n",
    "df.drop(columns=['datetime'],inplace=True)\n",
    "df1.drop(columns=['datetime'],inplace=True)\n",
    "df2.drop(columns=['datetime'],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**minimized dataset for our classification task, drop  rows for testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df['person'].value_counts(),'\\n',df['window_open'].value_counts(),'\\n')\n",
    "\n",
    "#### combine classes of more than 1 person to 1 person as there exists too little of them\n",
    "lc = df.loc[lambda x: x['person'] > 1]\n",
    "df.loc[lc.index,'person'] = 1\n",
    "\n",
    "lc = df1.loc[lambda x: x['person'] > 1]\n",
    "df1.loc[lc.index,'person'] = 1\n",
    "\n",
    "lc = df2.loc[lambda x: x['person'] > 1]\n",
    "df2.loc[lc.index,'person'] = 1\n",
    "\n",
    "print(df['person'].value_counts(),'\\n',df['window_open'].value_counts(),'\\n')\n",
    "\n",
    "\n",
    "############### drop  rows for testing\n",
    "### november (one month) for testing\n",
    "df2_test = df2.iloc[df2.shape[0]-22000:df2.shape[0]-21700] ## to get better visualization on less focused data\n",
    "datetime_test = datetime_df2.iloc[datetime_df2.shape[0]-22000:datetime_df2.shape[0]-21700]\n",
    "df2 = df2.drop(index = df2.index[df2.shape[0]-22000:]) ### to keep the sequence order drop from last\n",
    "datetime_df2 = datetime_df2.drop(index = datetime_df2.index[datetime_df2.shape[0]-22000:])\n",
    "\n",
    "\n",
    "### for visualization\n",
    "datetime_train = concat(datetime_df1,datetime_df2)\n",
    "df_train = concat(df1,df2)\n",
    "df_train.columns=df1.columns\n",
    "\n",
    "# df2.reset_index(drop=True,inplace=True)\n",
    "# df2_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df2_test_targets = df2_test.filter(['person','window_open'])\n",
    "df2_test_features = df2_test.drop(columns=['person','window_open']) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "targets = df.filter(['person','window_open'])\n",
    "features = df.drop(columns=['person','window_open']) \n",
    "\n",
    "\n",
    "targets1 = df1.filter(['person','window_open'])\n",
    "features1 = df1.drop(columns=['person','window_open']) \n",
    "\n",
    "targets2 = df2.filter(['person','window_open'])\n",
    "features2 = df2.drop(columns=['person','window_open']) \n",
    "\n",
    "\n",
    "\n",
    "### minimized data\n",
    "l_ = ['humidity','temperature','tvoc','oxygen','co2','co','pressure','o3','sound','person','window_open']\n",
    "f_ = ['humidity','temperature','tvoc','oxygen','co2','co','pressure','o3','sound']\n",
    "### from leipzig data\n",
    "# l_ = ['humidity_abs','temperature','tvoc','oxygen','co2','co','no2','o3','person','window_open']\n",
    "# f_ = ['humidity_abs','temperature','tvoc','oxygen','co2','co','no2','o3']\n",
    "\n",
    "df_mini1 = df1.filter(l_)\n",
    "print(df_mini1.shape,'\\n',df_mini1['person'].value_counts(),'\\n',df_mini1['window_open'].value_counts(),'\\n')\n",
    "features_mini1 = features1.filter(f_)\n",
    "# print(targets1.iloc[:,0].value_counts())\n",
    "\n",
    "df_mini2 = df2.filter(l_)\n",
    "print(df_mini2.shape,'\\n',df_mini2['person'].value_counts(),'\\n',df_mini2['window_open'].value_counts(),'\\n')\n",
    "features_mini2 = features2.filter(f_)\n",
    "# print(targets2.iloc[:,0].value_counts())\n",
    "\n",
    "df2_test_mini = df2_test.filter(l_)\n",
    "print(df2_test_mini.shape,'\\n',df2_test_mini['person'].value_counts(),'\\n',df2_test_mini['window_open'].value_counts(),'\\n')\n",
    "df2_test_features_mini = df2_test_features.filter(f_)\n",
    "\n",
    "## whole df\n",
    "df_mini = df.filter(l_)\n",
    "print(df_mini.shape,'\\n',df_mini['person'].value_counts(),'\\n',df_mini['window_open'].value_counts(),'\\n')\n",
    "features_mini = features.filter(f_)\n",
    "# print(targets2.iloc[:,0].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform undersampling and segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_LSTM.yaml') as f:\n",
    "    hyperparams = yaml.load(f,SafeLoader)\n",
    "    \n",
    "under_window = hyperparams['sample_segment']['under_window']\n",
    "seq_len = hyperparams['sample_segment']['seq_len']\n",
    "stride = hyperparams['sample_segment']['stride']\n",
    "sliding_mode = hyperparams['sample_segment']['sliding_mode']\n",
    "all_features = hyperparams['sample_segment']['all_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "under sample and segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## undersampling and sliding\n",
    "sampling = hyperparams['sample_segment']['sampling']\n",
    "if sampling:\n",
    "    if all_features:\n",
    "        X1,y1= under_sample(df1,under_window,seq_len,stride,sliding_mode=sliding_mode)\n",
    "        X2,y2= under_sample(df2,under_window,seq_len,stride,sliding_mode=sliding_mode)\n",
    "    else:\n",
    "        X1,y1= under_sample(df_mini1,under_window,seq_len,stride,sliding_mode=sliding_mode)\n",
    "        X2,y2= under_sample(df_mini2,under_window,seq_len,stride,sliding_mode=sliding_mode)\n",
    "else:\n",
    "    if all_features:\n",
    "        X1,y1= sliding(seq_len,stride,features1,targets1,mode=sliding_mode)\n",
    "        X2,y2= sliding(seq_len,stride,features2,targets2,mode=sliding_mode)\n",
    "    else:\n",
    "        X1,y1= sliding(seq_len,stride,features_mini1,targets1,mode=sliding_mode)\n",
    "        X2,y2= sliding(seq_len,stride,features_mini2,targets2,mode=sliding_mode)\n",
    "\n",
    "\n",
    "\n",
    "X = concat(X1,X2)\n",
    "y = concat(y1,y2)\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**splitting sets and standardization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### splitting\n",
    "# splits = TrainValidTestSplitter(valid_size=0.2,test_size=0.1)(y) ##### we have test set here\n",
    "splits = TrainValidTestSplitter(valid_size=0.1)(y) ##### we DON'T have test set here\n",
    "x_train = np.zeros(X[splits[0]].shape,dtype=np.float32)\n",
    "y_train = y[splits[0]]\n",
    "x_valid = np.zeros(X[splits[1]].shape,dtype=np.float32)\n",
    "y_valid = y[splits[1]]\n",
    "#### if splitted\n",
    "# x_test = np.zeros(X[splits[2]].shape,dtype=np.float32)\n",
    "# y_test = y[splits[2]]\n",
    "\n",
    "#different test set\n",
    "### uses stride = 1 to check all time points\n",
    "if all_features:\n",
    "    x_test_, y_test = sliding(seq_len,1,df2_test_features,df2_test_targets,mode=sliding_mode)\n",
    "else:\n",
    "    x_test_, y_test = sliding(seq_len,1,df2_test_features_mini,df2_test_targets,mode=sliding_mode)\n",
    "x_test = np.zeros(x_test_.shape,dtype=np.float32) \n",
    "#################\n",
    "\n",
    "\n",
    "\n",
    "#### standardization\n",
    "scalers = {}\n",
    "for i in range(x_train.shape[1]): ## n_features\n",
    "    scalers[i] = StandardScaler()\n",
    "    scalers[i].fit(np.unique((X[splits[0]])[:, i, :]).reshape(-1,1)) ### as we have overlapping samples\n",
    "    x_train[:, i, :] = scalers[i].transform((X[splits[0]])[:, i, :].reshape(-1,1)).reshape(x_train.shape[0],x_train.shape[-1])\n",
    "    x_valid[:, i, :] = scalers[i].transform((X[splits[1]])[:, i, :].reshape(-1,1)).reshape(x_valid.shape[0],x_valid.shape[-1])\n",
    "    # x_test[:, i, :] = scalers[i].transform((X[splits[2]])[:, i, :].reshape(-1,1)).reshape(x_test.shape[0],x_test.shape[-1]) ## from splitting\n",
    "    x_test[:, i, :] = scalers[i].transform((x_test_)[:, i, :].reshape(-1,1)).reshape(x_test.shape[0],x_test.shape[-1]) ## test set from outside\n",
    "print(x_train.shape,x_valid.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tsai LEARNER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_LSTM.yaml') as f:\n",
    "    hyperparams = yaml.load(f,SafeLoader)\n",
    "\n",
    "epochs = hyperparams['model']['epochs']\n",
    "bs = hyperparams['model']['bs']\n",
    "num_workers = hyperparams['model']['num_workers']\n",
    "embed_size = hyperparams['model']['embed_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train (X_train, X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## remove sigmoid from the network*****************\n",
    "\n",
    "# tfms  = [None, Categorize()] ## single label\n",
    "tfms  = [None, MultiCategorize()] ## multi label\n",
    "batch_tfms = TSStandardize()\n",
    "\n",
    "## single label\n",
    "# tsets = TSDatasets(x_train, y_train[:,0], tfms=tfms, inplace=True)\n",
    "# vsets = TSDatasets(x_valid, y_valid[:,0], tfms=tfms, inplace=True)\n",
    "## multi label\n",
    "tsets = TSDatasets(x_train, y_train, tfms=tfms, inplace=True)\n",
    "vsets = TSDatasets(x_valid, y_valid, tfms=tfms, inplace=True)\n",
    "\n",
    "######################\n",
    "dls   = TSDataLoaders.from_dsets(tsets, vsets, bs = bs, num_workers=num_workers)#,batch_tfms=batch_tfms) ### note the normalization\n",
    "\n",
    "\n",
    "#############################################################\n",
    "k = {'hidden_size':22,'rnn_dropout':0.4}\n",
    "network = 'LSTM'\n",
    "\n",
    "model = create_model(MyLSTM, dls.vars,dls.c,dls,**k)\n",
    "# learn = Learner(dls, model, metrics=accuracy,cbs = ShowGraph()) ### single label\n",
    "#### note the accuracy_multi and MultiCategorize() contains BCEwithlogits not normal BCE\n",
    "learn = Learner(dls, model, metrics=F1_multi,cbs = ShowGraph(),lr = 1e-4 ) ### multi label\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "start = time.time()\n",
    "learn.fit_one_cycle(epochs,learn.lr_find().valley,cbs = EarlyStoppingCallback(monitor='valid_loss', min_delta=0.00001, patience=5)) ## learning rate annealing\n",
    "elapsed = time.time()-start\n",
    "print(f'time= {elapsed}')\n",
    "print(f'No. of trainable parameters= {count_parameters(model)}')\n",
    "print(f'train loss = {learn.recorder.values[-1][0]}, valid loss = {learn.recorder.values[-1][1]}')\n",
    "plt.figure()\n",
    "plt.plot(learn.recorder.lrs)\n",
    "\n",
    "print(learn.loss_func)\n",
    "metrics = np.array(learn.recorder.values)\n",
    "print('*** metrics: ' , learn.recorder.values[-1])\n",
    "\n",
    "# save the model as state dictionary \n",
    "torch.save(learn.model.state_dict(), f'{learn.model._get_name()}.pt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read already available networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfms  = [None, MultiCategorize()] ## multi label\n",
    "# batch_tfms = TSStandardize()\n",
    "\n",
    "# ## single label\n",
    "# # tsets = TSDatasets(x_train, y_train[:,0], tfms=tfms, inplace=True)\n",
    "# # vsets = TSDatasets(x_valid, y_valid[:,0], tfms=tfms, inplace=True)\n",
    "# ## multi label\n",
    "# tsets = TSDatasets(x_train, y_train, tfms=tfms, inplace=True)\n",
    "# vsets = TSDatasets(x_valid, y_valid, tfms=tfms, inplace=True)\n",
    "# ######################\n",
    "# dls   = TSDataLoaders.from_dsets(tsets, vsets, bs = bs, num_workers=num_workers)#,batch_tfms=batch_tfms) ### note the normalization\n",
    "\n",
    "\n",
    "# k = {'hidden_size':22,'rnn_dropout':0.4}\n",
    "# network = 'LSTM'\n",
    "\n",
    "\n",
    "# # load \n",
    "# pretrained_dict = torch.load(f'/afs/tu-chemnitz.de/home/urz/a/abom/internship/models/{MyLSTM.__name__}.pt')\n",
    "# model = create_model(MyLSTM, dls.vars,dls.c,dls,**k)\n",
    "# model.load_state_dict(pretrained_dict)\n",
    "\n",
    "# # learn = Learner(dls, model, metrics=accuracy,cbs = ShowGraph()) ### single label\n",
    "# #### note the accuracy_multi and MultiCategorize() contains BCEwithlogits not normal BCE\n",
    "# learn = Learner(dls, model, metrics=accuracy_multi,cbs = ShowGraph()) ### multi label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION ON TEST DATA SET + Using PR curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = learn.recorder.values\n",
    "print('before:', before)\n",
    "learn.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding dataset to apply same dls valid tfms on test\n",
    "def evaluate_test_data(_x_test, _y_test, _tfms,_learn):\n",
    "    x_test = _x_test\n",
    "    y_test = _y_test\n",
    "    tfms = _tfms\n",
    "    learn = _learn\n",
    "    ### standardize test set with train parameters (apply Multicategorize transform)\n",
    "    test_set = TSDatasets(x_test, y_test, tfms=tfms, inplace=True) # multi_label\n",
    "    # test_set = TSDatasets(x_test, y_test[:,0], tfms=tfms, inplace=True) # single_label\n",
    "    test_dl = TSDataLoader(test_set, bs = bs, num_workers=num_workers)#,batch_tfms=batch_tfms) ### note the normalization\n",
    "    # next(iter(test_dl))\n",
    "    \n",
    "\n",
    "    #### evaluating\n",
    "\n",
    "    test_probas, test_targets, test_preds = learn.get_preds(dl=test_dl,with_decoded=True)\n",
    "    test_preds = test_preds.long() ### to convert bool to int\n",
    "\n",
    "    ###############################################################################################\n",
    "    ###### use PR curve to get best threshold for each class on given test set\n",
    "    ##############################################################################################\n",
    "    # # # class person\n",
    "    # # threshold_person, _ = plot_PR_curve('person',test_targets[:,0],test_probas[:,0])\n",
    "    # # ### class window_open\n",
    "    # # threshold_window, _ =plot_PR_curve('window',test_targets[:,1],test_probas[:,1])\n",
    "    # threshold_person,threshold_window = plot_PR_curve_both(test_targets,test_probas)\n",
    "    # test_preds[:,0] = (test_probas[:,0]>=threshold_person)\n",
    "    # test_preds[:,1] = (test_probas[:,1]>=threshold_window)\n",
    "    #################################################################################################\n",
    "\n",
    "    ## single label\n",
    "    ### number of classes in validation set\n",
    "    # n_classes = pd.DataFrame(test_targets).value_counts().shape[0]\n",
    "    # plot_confusion(test_targets,test_preds,n_classes,name = 'person')\n",
    "    # print(f'Accuracy: {(test_targets == test_preds).float().mean():0.5f}')  \n",
    "    # print(f'F1 score: {f1_score(test_targets,test_preds)}\\n') # to get f1 score for each class use (average=None)\n",
    "    # print(f'precision: {precision_score(test_targets,test_preds)}\\n') \n",
    "    # print(f'recall: {recall_score(test_targets,test_preds)}\\n') \n",
    "\n",
    "    ## multi label\n",
    "    print(f'Accuracy [Both]: {(100/test_targets.shape[0])*torch.all((test_preds == test_targets),dim=1).sum():0.5f}') ## multi-label\n",
    "    print(f'Accuracy [person]: {(100/test_targets.shape[0])*(test_preds[:,0] == test_targets[:,0]).sum():0.5f}') ## multi-label\n",
    "    print(f'Accuracy [window_open]: {(100/test_targets.shape[0])*(test_preds[:,1] == test_targets[:,1]).sum():0.5f}') ## multi-label\n",
    "    n_classes = test_targets.shape[1]\n",
    "\n",
    "    ## confusion matrices\n",
    "    plot_confusion_both(test_targets,test_preds,n_classes)\n",
    "    ## person class\n",
    "    # plot_confusion(test_targets[:,0],test_preds[:,0],n_classes,name = 'person')\n",
    "    print(f'F1 score [person]: {f1_score(test_targets[:,0],test_preds[:,0])}\\n')\n",
    "    print(f'precision [person]: {precision_score(test_targets[:,0],test_preds[:,0])}\\n') \n",
    "    print(f'recall [person]: {recall_score(test_targets[:,0],test_preds[:,0])}\\n') \n",
    "\n",
    "    ### window class\n",
    "    # plot_confusion(test_targets[:,1],test_preds[:,1],n_classes,name = 'window')\n",
    "    print(f'F1 score [window]: {f1_score(test_targets[:,1],test_preds[:,1])}\\n') \n",
    "    print(f'precision [window]: {precision_score(test_targets[:,1],test_preds[:,1])}\\n') \n",
    "    print(f'recall [window]: {recall_score(test_targets[:,1],test_preds[:,1])}\\n') \n",
    "    \n",
    "    return test_targets,test_preds\n",
    "\n",
    "\n",
    "test_targets,test_preds = evaluate_test_data(_x_test= x_test, _y_test = y_test, _tfms = tfms,_learn = learn)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**investigate distribution of wrong predictions, and smoothing** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### single label\n",
    "# ## plot targets vs predictions person\n",
    "# plot_distribution(test_targets,test_preds,'person')\n",
    "# ## plot FP, FN \n",
    "# plot_fp_fn(test_targets,test_preds,'person')\n",
    "#############################################################################################################\n",
    "### smoothing\n",
    "# test_preds = smoothing_predictions(test_preds,2)\n",
    "###############################################################################################################\n",
    "#### multi label\n",
    "\n",
    "fig = plot_distribution_both(test_targets,test_preds, network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**optuna for HP optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_LSTM.yaml') as f:\n",
    "    hyperparams = yaml.load(f,SafeLoader)\n",
    "epochs = hyperparams['optuna']['epochs']\n",
    "optuna_trials = hyperparams['optuna']['trials']\n",
    "bs = hyperparams['model']['bs']\n",
    "num_workers = hyperparams['model']['num_workers']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimize (notice freeze for autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms  = [None, MultiCategorize()] \n",
    "batch_tfms = TSStandardize()\n",
    "\n",
    "\n",
    "tsets = TSDatasets(x_train, y_train, tfms=tfms, inplace=True)\n",
    "# vsets = TSDatasets(x_test, y_test, tfms=tfms, inplace=True)\n",
    "vsets = TSDatasets(x_valid, y_valid, tfms=tfms, inplace=True)\n",
    "\n",
    "dls   = TSDataLoaders.from_dsets(tsets, vsets, bs = bs, num_workers=num_workers)#,batch_tfms=batch_tfms) ### note the normalization\n",
    "\n",
    "\n",
    "def objective(trial:optuna.Trial):\n",
    "\n",
    "    rt = trial.study.study_name.replace('_LSTM_study','')\n",
    "    study_folder = f'/scratch/aifa/MyRepo/SmartAirsense/internship/TimeSeriesClassification/Experiments/LSTM/{rt}'\n",
    "    dat_ = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    trial_folder = os.path.join(study_folder,f'trial_{trial._trial_id}_{dat_}')\n",
    "    if not os.path.exists(trial_folder):\n",
    "        os.mkdir(trial_folder)\n",
    "    \n",
    "    # Define search space here. Supported search space are \n",
    "\n",
    "    rnn_dropout = trial.suggest_float(\"rnn_dropout\", 0.1, 0.5, step = 0.1)\n",
    "    hidden_size = trial.suggest_int('hidden_size',10,80,step = 2)\n",
    "    lr = trial.suggest_float(\"Learning_rate\", 1e-8, 1e-4, log=True)\n",
    "\n",
    "    k = {'hidden_size':hidden_size,'rnn_dropout':rnn_dropout}\n",
    "\n",
    "    model = create_model(MyLSTM, dls.vars,dls.c,dls,**k)\n",
    "    #### note the F1_multi and MultiCategorize() contains BCEwithlogits not normal BCE\n",
    "    learn = Learner(dls, model, metrics=F1_multi, lr=lr)\n",
    " \n",
    "    ######################################\n",
    "    learn.fit_one_cycle(epochs,learn.lr_find().valley,cbs = EarlyStoppingCallback(monitor='valid_loss', min_delta=0.00001, patience=5)) ## learning rate annealing\n",
    "    \n",
    "    # # return the F1 score - learn.recorder.values returns [[train_loss, valid_loss, F1_multi]]\n",
    "    metric_before_pred = learn.recorder.values[-1][-1]\n",
    "    \n",
    "    print('****** before_plot: ', learn.recorder.values[-1])\n",
    "    test_targets,test_preds = evaluate_test_data(_x_test= x_test, _y_test = y_test, _tfms = tfms,_learn = learn)\n",
    "    fig = plot_distribution_both(test_targets,test_preds, network='LSTM')\n",
    "    fig.savefig(os.path.join(trial_folder, 'plot_dist.png'))\n",
    "    print('****** after_plot: ', learn.recorder.values[-1])\n",
    "    \n",
    "    trial_params = os.path.join(trial_folder,'trial_params.yaml')\n",
    "    with open(trial_params,'w') as f:\n",
    "        for key, value in trial.params.items():\n",
    "            f.write(\"    {}: {}\\n\".format(key, value))\n",
    "    \n",
    "    return metric_before_pred\n",
    "    # # return the F1 score - learn.recorder.values returns [[train_loss, valid_loss, F1_multi]]\n",
    "    # return learn.recorder.values[-1][-1]\n",
    "\n",
    "    # # return the valid_loss - learn.recorder.values returns [[train_loss, valid_loss, acc]]\n",
    "    # return learn.recorder.values[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "lstm_folder = f'/scratch/aifa/MyRepo/SmartAirsense/internship/TimeSeriesClassification/Experiments/LSTM/{dat}'\n",
    "if not os.path.exists(lstm_folder):\n",
    "    os.mkdir(lstm_folder)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', \n",
    "                            pruner=optuna.pruners.HyperbandPruner(),\n",
    "                            storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=f\"{dat}_LSTM_study\")\n",
    "\n",
    "study.optimize(objective, n_trials=optuna_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "best_trial_params = os.path.join(lstm_folder,'best_trial_params.yaml')\n",
    "with open(best_trial_params,'w') as f:\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(\"    {}: {}\\n\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimization_history = optuna.visualization.plot_optimization_history(study)\n",
    "param_importances = optuna.visualization.plot_param_importances(study)\n",
    "slice = optuna.visualization.plot_slice(study)\n",
    "parallel_coordinate = optuna.visualization.plot_parallel_coordinate(study)\n",
    "\n",
    "optimization_history.write_image(os.path.join(lstm_folder,'optimization_history.png'))\n",
    "param_importances.write_image(os.path.join(lstm_folder,'param_importances.png'))\n",
    "slice.write_image(os.path.join(lstm_folder,'slice.png'))\n",
    "parallel_coordinate.write_image(os.path.join(lstm_folder,'parallel_coordinate.png'))\n",
    "\n",
    "display(optimization_history)\n",
    "display(param_importances)\n",
    "display(slice)\n",
    "display(parallel_coordinate)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airsense_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "94cf76cf85553c7b9a14c1c8fafc95b4e781f4dc7651d74bc0dd1329c9745b2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
